{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Deconv2D,Conv2D,BatchNormalization,Activation,Concatenate,Reshape\n",
    "from keras.engine.topology import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. conv/deconv networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_input(img_w,img_h,img_c):\n",
    "    frame_t0=tf.placeholder(tf.float32,(None,img_w,img_h,img_c),name='frame_t0')\n",
    "    frame_t1=tf.placeholder(tf.float32,(None,img_w,img_h,img_c),name='frame_t1')\n",
    "    learning_rate=tf.placeholder(tf.float32)\n",
    "    \n",
    "    return frame_t0,frame_t1,learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_w,img_h,img_c=384,128,3\n",
    "frame_t0,frame_t1,learning_rate=model_input(img_w,img_h,img_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv(h_0,filters,kernel_size,strides):\n",
    "        h1=Conv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding='same')(h_0)\n",
    "        h1_bn=BatchNormalization()(h1,training=True)\n",
    "        h1_o=Activation(K.relu)(h1_bn)\n",
    "        return h1_o\n",
    "def deconv(h_0,filters,kernel_size,strides):\n",
    "        h1=Deconv2D(filters=filters,kernel_size=kernel_size,strides=strides,padding='same')(h_0)\n",
    "        h1_bn=BatchNormalization()(h1,training=True)\n",
    "        h1_o=Activation(K.relu)(h1_bn)\n",
    "        return h1_o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def conv_deconv_net(frame,name, reuse=False,alpha=0.2,):\n",
    "    with tf.variable_scope(name,reuse=reuse):\n",
    "        \n",
    "        ###to deconv\n",
    "        h10_o=conv(frame,filters=32,kernel_size=3,strides=1)\n",
    "\n",
    "        h11_o=conv(h10_o,filters=64,kernel_size=3,strides=2)\n",
    "        ###to deconv\n",
    "        h20_o=conv(h11_o,filters=64,kernel_size=3,strides=1)\n",
    "        \n",
    "        h21_o=conv(h20_o,filters=128,kernel_size=3,strides=2)\n",
    "        \n",
    "        ###to deconv\n",
    "        h30_o=conv(h21_o,filters=128,kernel_size=3,strides=1)\n",
    "        \n",
    "        h31_o=conv(h30_o,filters=256,kernel_size=3,strides=2)\n",
    "        ###to deconv\n",
    "        h40_o=conv(h31_o,filters=256,kernel_size=3,strides=1)\n",
    "        \n",
    "        h41_o=conv(h40_o,filters=512,kernel_size=3,strides=2)\n",
    "        ###to deconv\n",
    "        h50_o=conv(h41_o,filters=512,kernel_size=3,strides=1)\n",
    "        \n",
    "        h51_o=conv(h50_o,filters=1024,kernel_size=3,strides=2)\n",
    "        h60_o=conv(h51_o,filters=1024,kernel_size=3,strides=1)\n",
    "        \n",
    "        \n",
    "        #deconv\n",
    "        d5=deconv(h60_o,filters=512,kernel_size=3,strides=2)\n",
    "        d4_i=Concatenate(axis=-1)([d5,h50_o])\n",
    "        \n",
    "        d4=deconv(d4_i,filters=256,kernel_size=3,strides=2)\n",
    "        \n",
    "        d3_i=Concatenate(axis=-1)([d4,h40_o])\n",
    "        \n",
    "        d3=deconv(d3_i,filters=128,kernel_size=3,strides=2)\n",
    "        \n",
    "        \n",
    "        \n",
    "        d2_i=Concatenate(axis=-1)([d3,h30_o])\n",
    "        \n",
    "        d2=deconv(d2_i,filters=64,kernel_size=3,strides=2)\n",
    "        \n",
    "        \n",
    "        d1_i=Concatenate(axis=-1)([d2,h20_o])\n",
    "        \n",
    "        out=deconv(d1_i,filters=32,kernel_size=3,strides=2)\n",
    "        \n",
    "        \n",
    "        return out,h60_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Activation at 0x7f08c8fe5b70>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def drelu(x):\n",
    "    x=K.relu(x,max_value=99)\n",
    "    shape=x.shape.as_list()\n",
    "    bias=K.ones(shape[-1:])\n",
    "    x=K.bias_add(x,bias)\n",
    "    \n",
    "    \n",
    "    return x\n",
    "\n",
    "Activation(drelu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. STRUCTURE NETWORK\n",
    "### 2.1 Depth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def depth_net(frame_t0,name='depth_net'):\n",
    "    top,_=conv_deconv_net(frame_t0,name)\n",
    "    top=Conv2D(filters=1,kernel_size=1,strides=1,padding='same')(top)\n",
    "    depth=Activation(drelu)(top)\n",
    "    \n",
    "    return depth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unit_test(inputshape,input_num,model):\n",
    "    input_data=[tf.ones(inputshape) for i in range(input_num)]\n",
    "    out=model(*input_data)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out_=sess.run(out)\n",
    "    return out,out_\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputshape=[2,384,128,3]\n",
    "input_num=1\n",
    "model=depth_net\n",
    "depth,_=unit_test(inputshape,input_num,model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Depth to  point clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Cloud_transformer():\n",
    "\n",
    "    def __init__(self, output_dim,intrinsics=[0.5,0.5,1.0], **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.cam_intrinsics = intrinsics\n",
    "        self.build()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def build(self):\n",
    "        self.cx_=self.cam_intrinsics[0]\n",
    "        \n",
    "        self.cy_=self.cam_intrinsics[1]\n",
    "        \n",
    "        self.cf_=self.cam_intrinsics[2]\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.cx=tf.constant(self.cam_intrinsics[0],dtype=tf.float32)\n",
    "        \n",
    "        self.cy=tf.constant(self.cam_intrinsics[1],dtype=tf.float32)\n",
    "        \n",
    "        self.cf=tf.constant(self.cam_intrinsics[2],dtype=tf.float32)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Create a trainable weight variable for this layer.\n",
    "        \n",
    "        \n",
    "    def mesh_grid(self,width,height):\n",
    "        x_linspace=tf.linspace(-self.cx_,1-self.cx_,width)\n",
    "        y_linspace=tf.linspace(-self.cy_,1-self.cy_,height)\n",
    "        \n",
    "        x_cord,y_cord=tf.meshgrid(x_linspace,y_linspace)\n",
    "        \n",
    "        x_cord=tf.reshape(x_cord,[-1])\n",
    "        y_cord=tf.reshape(y_cord,[-1])\n",
    "        \n",
    "        f_=tf.ones_like(x_cord)\n",
    "        \n",
    "        x_=tf.div(x_cord,self.cf)\n",
    "        y_=tf.div(y_cord,self.cf)\n",
    "        \n",
    "        pc2=tf.concat([x_,y_,f_],0)\n",
    "        return pc2\n",
    "        \n",
    "        \n",
    "    def transform(self,x):\n",
    "        \n",
    "        #get input shape\n",
    "        batch_size=tf.shape(x)[0]\n",
    "        width=tf.shape(x)[1]\n",
    "        height=tf.shape(x)[2]\n",
    "        channel=tf.shape(x)[3]\n",
    "        batch_size=tf.cast(batch_size,tf.int32)\n",
    "        width=tf.cast(width,tf.int32)\n",
    "        height=tf.cast(height,tf.int32)\n",
    "        channel=tf.cast(channel,tf.int32)\n",
    "        \n",
    "        \n",
    "        #grid\n",
    "        grid=self.mesh_grid(width,height)\n",
    "        pc2=tf.expand_dims(grid,0)\n",
    "        pc2=tf.reshape(pc2,[-1])\n",
    "        \n",
    "        \n",
    "        pc2 = tf.tile(pc2, tf.stack([batch_size]))\n",
    "        pc2=tf.reshape(pc2,[batch_size,3,-1])\n",
    "        \n",
    "        depth=tf.reshape(x,[batch_size,1,-1])\n",
    "        depth=tf.concat([depth]*self.output_dim,1)\n",
    "        \n",
    "        pc3=tf.multiply(depth,pc2)\n",
    "#         pc3=tf.reshape(pc3,[batch_size,width,height,self.output_dim])\n",
    "        \n",
    "        \n",
    "        return pc2\n",
    "        \n",
    "\n",
    "    def __call__(self, x):\n",
    "        pc3=self.transform(x)\n",
    "        return pc3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inputshape=[2,384,128,3]\n",
    "input_num=1\n",
    "model=Cloud_transformer(3)\n",
    "pc3,pc3_=unit_test(inputshape,input_num,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scene motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def angle_relu(x):\n",
    "    x=K.relu(x,max_value=2)\n",
    "    shape=x.shape.as_list()\n",
    "    bias=K.ones(shape[-1:])\n",
    "    x=tf.subtract(x,bias)\n",
    "    \n",
    "    \n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def motion_net(frame_t0,frame_t1,k_obj=4,name='motion'):\n",
    "    top,embed=conv_deconv_net(frame_t0,name)\n",
    "    top=Conv2D(filters=k_obj,kernel_size=1,strides=1,padding='same')(top)\n",
    "    \n",
    "    \n",
    "    embed=Dense(512)(embed)\n",
    "    embed=Dense(512)(embed)\n",
    "    embed=Reshape([-1])(embed)\n",
    "    \n",
    "    \n",
    "    cam_t_=Dense(3)(embed)\n",
    "    cam_t=Activation('relu')(cam_t_)\n",
    "    cam_p=Dense(3)(embed)\n",
    "    \n",
    "    cam_p=Activation('relu')(cam_p)\n",
    "    cam_r=Dense(3)(embed)\n",
    "    \n",
    "    cam_r=Activation(angle_relu)(cam_r)\n",
    "    \n",
    "    \n",
    "    \n",
    "    motion_mask= Activation('sigmoid')(top) \n",
    "    motion_t=Activation('relu')(Dense(3*k_obj)(embed))\n",
    "    motion_t=tf.reshape(motion_t,(-1,k_obj,3))\n",
    "    motion_p=Activation('relu')(Dense(3*k_obj)(embed))\n",
    "    motion_p=tf.reshape(motion_p,(-1,k_obj,3))\n",
    "    \n",
    "    motion_r=Activation(angle_relu)(Dense(3*k_obj)(embed))\n",
    "    motion_r=tf.reshape(motion_r,(-1,k_obj,3))\n",
    "    \n",
    "    return [cam_t,cam_p,cam_r],[motion_t,motion_p, motion_r,motion_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "inputshape=[2,384,128,3]\n",
    "input_num=2\n",
    "model=motion_net\n",
    "motios,motios_=unit_test(inputshape,input_num,model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Optical_transformer():\n",
    "\n",
    "    def __init__(self,intrinsics=[0.5,0.5,1.0], **kwargs):\n",
    "        \n",
    "        self.cam_intrinsics = intrinsics\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.cx_=self.cam_intrinsics[0]\n",
    "        \n",
    "        self.cy_=self.cam_intrinsics[1]\n",
    "        \n",
    "        self.cf_=self.cam_intrinsics[2]\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.cx=self.np_tf(self.cam_intrinsics[0])\n",
    "        \n",
    "        self.cy=self.np_tf(self.cam_intrinsics[1])\n",
    "        \n",
    "        self.cf=self.np_tf(self.cam_intrinsics[2])\n",
    "        \n",
    "        \n",
    "        \n",
    "                # so3\n",
    "        \n",
    "        so3_a=np.array([\n",
    "            [0,-1,0,1,0,0,0,0,0],\n",
    "            [1,0,0,0,1,0,0,0,0],\n",
    "            [0,0,0,0,0,0,0,0,1]\n",
    "        ])\n",
    "\n",
    "        so3_b=np.array([\n",
    "            [0,0,1,0,0,0,-1,0,0],\n",
    "            [1,0,0,0,0,0,0,0,1],\n",
    "            [0,0,0,0,1,0,0,0,0]\n",
    "        ])\n",
    "\n",
    "        so3_y=np.array([\n",
    "            [0,0,0,0,0,-1,0,1,0],\n",
    "            [0,0,0,0,1,0,0,0,1],\n",
    "            [1,0,0,0,0,0,0,0,0]\n",
    "        ])\n",
    "\n",
    "#         so3_param=np.concatenate([so3_a,so3_b,so3_y],0)\n",
    "        self.so3_a=self.np_tf(so3_a)\n",
    "        self.so3_b=self.np_tf(so3_b)\n",
    "        self.so3_y=self.np_tf(so3_y)\n",
    "        \n",
    "\n",
    "        \n",
    "#     tool    \n",
    "    def np_tf(self,array):\n",
    "        return tf.constant(array,tf.float32)\n",
    "    \n",
    "\n",
    "    def build(self,cam_motion,obj_motion,x):\n",
    "                \n",
    "        self.cam_motion=cam_motion\n",
    "        \n",
    "        self.obj_motion=obj_motion\n",
    "        self.mask_size=obj_motion[0].shape.as_list()[1]\n",
    "        self.x_shape=x.shape.as_list()\n",
    "        \n",
    "#    tranformation     \n",
    "    def so3_mat(self,sin):\n",
    "        #input :sin a,sin b,sin y \n",
    "        #return : SO3\n",
    "        sin=tf.expand_dims(sin,-1)\n",
    "        cos=tf.sqrt(tf.ones_like(sin)-tf.square(sin))\n",
    "        t=tf.concat([sin,cos,tf.ones_like(sin)],-1)\n",
    "        t_a=tf.slice(t,[0,0,0],[-1,1,-1])\n",
    "        t_b=tf.slice(t,[0,1,0],[-1,1,-1])\n",
    "        t_y=tf.slice(t,[0,2,0],[-1,1,-1])\n",
    "        t_a=tf.reshape(t_a,(-1,3))\n",
    "        t_b=tf.reshape(t_b,(-1,3))\n",
    "        t_y=tf.reshape(t_y,(-1,3))\n",
    "        \n",
    "        soa=tf.matmul(t_a,self.so3_a)\n",
    "        soa=tf.reshape(soa,(-1,3,3))\n",
    "        \n",
    "        sob=tf.matmul(t_b,self.so3_b)\n",
    "        sob=tf.reshape(sob,(-1,3,3))\n",
    "        soy=tf.matmul(t_y,self.so3_y)\n",
    "        soy=tf.reshape(soy,(-1,3,3))\n",
    "        \n",
    "        \n",
    "        \n",
    "        so3=tf.matmul(soy,  tf.matmul(soa,sob))\n",
    "        return so3\n",
    "    \n",
    "    def rigid_motion(self,x,R,p,t):\n",
    "        p=tf.expand_dims(p,-1)\n",
    "        t=tf.expand_dims(t,-1)\n",
    "        \n",
    "        \n",
    "        motion=tf.add(tf.matmul(R,tf.subtract(x,p)),t)\n",
    "        \n",
    "\n",
    "        return motion\n",
    "    \n",
    "    def cam_motion_transform(self,x):\n",
    "        t,p,sin=self.cam_motion\n",
    "        R=self.so3_mat(sin)\n",
    "        X=self.rigid_motion(x,R,p,t)\n",
    "        \n",
    "        \n",
    "        return X\n",
    "\n",
    "    def obj_motion_transform(self,x_input):\n",
    "        t,p,sin,mask=self.obj_motion\n",
    "        \n",
    "        sin=tf.reshape(sin,(-1,3))\n",
    "        p=tf.reshape(p,(-1,3))\n",
    "        t=tf.reshape(t,(-1,3))\n",
    "        x_in=tf.expand_dims(x_input,1)\n",
    "        x_exp=tf.concat([x_in]*self.mask_size,1)\n",
    "        x_=tf.reshape(x_exp,(-1,3,384*128))\n",
    "        \n",
    "        \n",
    "        R=self.so3_mat(sin)\n",
    "        \n",
    "        x=self.rigid_motion(x_,R,p,t)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x=tf.reshape(x,(-1,self.mask_size,3,384*128))\n",
    "        x=self.mask_motion(x,mask,x_exp)\n",
    "        X=tf.add(x_input,x)\n",
    "        \n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def mask_motion(self,x,mask,x_exp):\n",
    "        mask=tf.reshape(mask,(-1,self.mask_size,1,384*128))\n",
    "        x=tf.subtract(x,x_exp)\n",
    "        x=tf.multiply(x,mask)\n",
    "        x=tf.reshape(x,(-1,self.mask_size,3,384*128))\n",
    "        x=tf.reduce_sum(x,1)\n",
    "        print(x.shape.as_list())\n",
    "        \n",
    "        return x\n",
    "  \n",
    "    def __call__(self,x,cam_motion,obj_motion,):\n",
    "        self.build( cam_motion,obj_motion,x)\n",
    "\n",
    "        \n",
    "        X=self.obj_motion_transform(x)\n",
    "        \n",
    "        \n",
    "#         X=self.cam_motion_transform(x)\n",
    "        return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 49152]\n",
      "x_in [None, 1, 3, None]\n"
     ]
    }
   ],
   "source": [
    "cam,obj=motios\n",
    "x=pc3\n",
    "rgid_=Optical_transformer()(x,cam,obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgid_motion=sess.run(rgid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 49152)"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgid_motion.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
